{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "776b8c0d-6af2-47a7-8537-e938ae95d10b",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-03-12T05:27:20.975730Z",
     "iopub.status.busy": "2024-03-12T05:27:20.975582Z",
     "iopub.status.idle": "2024-03-12T05:27:21.249775Z",
     "shell.execute_reply": "2024-03-12T05:27:21.249368Z",
     "shell.execute_reply.started": "2024-03-12T05:27:20.975713Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha  Composition_code.py  FG\ttraining_bg_names.txt  training_fg_names.txt\n"
     ]
    }
   ],
   "source": [
    "!ls /mnt/data/Train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72e6c270-a554-4dd8-b2c1-62a594e45eaf",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-03-12T05:27:21.250545Z",
     "iopub.status.busy": "2024-03-12T05:27:21.250336Z",
     "iopub.status.idle": "2024-03-12T05:27:21.253007Z",
     "shell.execute_reply": "2024-03-12T05:27:21.252509Z",
     "shell.execute_reply.started": "2024-03-12T05:27:21.250529Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip3 install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac6a2bf1-8448-42e5-8ed7-627a8bf4f0ff",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-03-12T05:27:21.253759Z",
     "iopub.status.busy": "2024-03-12T05:27:21.253554Z",
     "iopub.status.idle": "2024-03-12T05:27:22.819777Z",
     "shell.execute_reply": "2024-03-12T05:27:22.819318Z",
     "shell.execute_reply.started": "2024-03-12T05:27:21.253744Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.models.modnet import MODNet\n",
    "from src.trainer import supervised_training_iter\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from skimage import morphology\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "import torch.nn.functional as F\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93f61526-d879-4bab-80df-a9a5db4bd910",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-03-12T05:27:22.821495Z",
     "iopub.status.busy": "2024-03-12T05:27:22.821165Z",
     "iopub.status.idle": "2024-03-12T05:27:23.931036Z",
     "shell.execute_reply": "2024-03-12T05:27:23.930611Z",
     "shell.execute_reply.started": "2024-03-12T05:27:22.821478Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FG</th>\n",
       "      <th>Alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/mnt/data/Train/FG/0000.png</td>\n",
       "      <td>/mnt/data/Train/Alpha/0000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/mnt/data/Train/FG/0001.png</td>\n",
       "      <td>/mnt/data/Train/Alpha/0001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/mnt/data/Train/FG/0002.png</td>\n",
       "      <td>/mnt/data/Train/Alpha/0002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/mnt/data/Train/FG/0003.png</td>\n",
       "      <td>/mnt/data/Train/Alpha/0003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/mnt/data/Train/FG/0004.png</td>\n",
       "      <td>/mnt/data/Train/Alpha/0004.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            FG                           Alpha\n",
       "0  /mnt/data/Train/FG/0000.png  /mnt/data/Train/Alpha/0000.png\n",
       "1  /mnt/data/Train/FG/0001.png  /mnt/data/Train/Alpha/0001.png\n",
       "2  /mnt/data/Train/FG/0002.png  /mnt/data/Train/Alpha/0002.png\n",
       "3  /mnt/data/Train/FG/0003.png  /mnt/data/Train/Alpha/0003.png\n",
       "4  /mnt/data/Train/FG/0004.png  /mnt/data/Train/Alpha/0004.png"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Set the base path for the dataset\n",
    "base_path = Path(\"/mnt/data/Train/\")\n",
    "\n",
    "# Correcting the approach to construct the DataFrame without using 'append' in a loop\n",
    "\n",
    "# Re-list the FG and Alpha images in case there was an issue with the initial listing\n",
    "fg_images = list((base_path / \"FG\").rglob(\"*.*\"))\n",
    "alpha_images = list((base_path / \"Alpha\").rglob(\"*.*\"))\n",
    "\n",
    "# Initialize lists for holding the matched file paths\n",
    "fg_file_paths = []\n",
    "alpha_file_paths = []\n",
    "\n",
    "# Map of alpha files for quick lookup by name\n",
    "alpha_files_map = {alpha_image.name: alpha_image for alpha_image in alpha_images}\n",
    "\n",
    "# Iterate over FG images and find corresponding Alpha images by name\n",
    "for fg_image_path in fg_images:\n",
    "    file_name = fg_image_path.name\n",
    "    if file_name in alpha_files_map:\n",
    "        # If the corresponding Alpha file is found, add both paths to the lists\n",
    "        fg_file_paths.append(str(fg_image_path))\n",
    "        alpha_file_paths.append(str(alpha_files_map[file_name]))\n",
    "\n",
    "# Create the DataFrame directly from the lists of file paths\n",
    "df_files_corrected = pd.DataFrame({\n",
    "    \"FG\": fg_file_paths,\n",
    "    \"Alpha\": alpha_file_paths\n",
    "})\n",
    "\n",
    "df_files_corrected.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d25c604-ef46-46ba-a2ae-98e30f0529ae",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-03-12T05:27:23.931849Z",
     "iopub.status.busy": "2024-03-12T05:27:23.931623Z",
     "iopub.status.idle": "2024-03-12T05:27:23.941566Z",
     "shell.execute_reply": "2024-03-12T05:27:23.941160Z",
     "shell.execute_reply.started": "2024-03-12T05:27:23.931833Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModNetDataLoader(Dataset):\n",
    "    def __init__(self, annotations_file, resize_dim, transform=None):\n",
    "        self.img_labels =annotations_file\n",
    "        self.transform=transform\n",
    "        self.resize_dim=resize_dim\n",
    "\n",
    "    def __len__(self):\n",
    "        #return the total number of images\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #print(idx)\n",
    "        img_path = self.img_labels.iloc[idx,0]\n",
    "        mask_path = self.img_labels.iloc[idx,1]\n",
    "        #print(img_path,mask_path)\n",
    "        temp_image = Image.open(img_path)\n",
    "        #temp_image.show()\n",
    "        img = np.asarray(temp_image)\n",
    "        #display(img_path)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)\n",
    "        #stupid = Image.open(mask_path)\n",
    "        #stupid.show()\n",
    "        #print(img.shape)\n",
    "        #print(in_image.shape)\n",
    "        #mask = in_image[:,:,3]\n",
    "        \n",
    "\n",
    "        if len(img.shape)==2:\n",
    "            img = img[:,:,None]\n",
    "        if img.shape[2]==1:\n",
    "            img = np.repeat(img, 3, axis=2)\n",
    "        elif img.shape[2]==4:\n",
    "            img = img[:,:,0:3]\n",
    "\n",
    "        if len(mask.shape)==3:\n",
    "            mask = mask[:,:, 0]\n",
    "\n",
    "        #convert Image to pytorch tensor\n",
    "        img = Image.fromarray(img)\n",
    "        mask = Image.fromarray(mask)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            trimap = self.get_trimap(mask)\n",
    "            mask = self.transform(mask)\n",
    "\n",
    "        img = self._resize(img)\n",
    "        mask = self._resize(mask)\n",
    "        trimap = self._resize(trimap, trimap=True)\n",
    "\n",
    "        img = torch.squeeze(img, 0)\n",
    "        mask = torch.squeeze(mask, 0)\n",
    "        trimap = torch.squeeze(trimap, 1)\n",
    "        #print(img.shape,trimap.shape,mask.shape)\n",
    "        return img.cuda(), trimap.cuda(), mask.cuda()\n",
    "\n",
    "    def get_trimap(self, alpha):\n",
    "        # alpha \\in [0, 1] should be taken into account\n",
    "        # be careful when dealing with regions of alpha=0 and alpha=1\n",
    "        fg = np.array(np.equal(alpha, 255).astype(np.float32))\n",
    "        unknown = np.array(np.not_equal(alpha, 0).astype(np.float32)) # unknown = alpha > 0\n",
    "        unknown = unknown - fg\n",
    "        # image dilation implemented by Euclidean distance transform\n",
    "        unknown = distance_transform_edt(unknown==0) <= np.random.randint(1, 20)\n",
    "        trimap = fg\n",
    "        trimap[unknown] = 0.5\n",
    "        return torch.unsqueeze(torch.from_numpy(trimap), dim=0)#.astype(np.uint8)\n",
    "\n",
    "    def _resize(self, img, trimap=False):\n",
    "        im = img[None, :, :, :]\n",
    "        ref_size = self.resize_dim\n",
    "\n",
    "        # resize image for input\n",
    "        im_b, im_c, im_h, im_w = im.shape\n",
    "        if max(im_h, im_w) < ref_size or min(im_h, im_w) > ref_size:\n",
    "            if im_w >= im_h:\n",
    "                im_rh = ref_size\n",
    "                im_rw = int(im_w / im_h * ref_size)\n",
    "            elif im_w < im_h:\n",
    "                im_rw = ref_size\n",
    "                im_rh = int(im_h / im_w * ref_size)\n",
    "        else:\n",
    "            im_rh = im_h\n",
    "            im_rw = im_w\n",
    "\n",
    "        im_rw = im_rw - im_rw % 32\n",
    "        im_rh = im_rh - im_rh % 32\n",
    "        im_rw=512\n",
    "        im_rh=512\n",
    "        if trimap == True:\n",
    "            im = F.interpolate(im, size=(im_rh, im_rw), mode='nearest')\n",
    "        else:\n",
    "            im = F.interpolate(im, size=(im_rh, im_rw), mode='area')\n",
    "        #imb =transforms.ToPILImage()(im.squeeze().cpu())\n",
    "        #imb.show()\n",
    "        return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29a7c295-cd2d-4e87-8aa4-787e0ed75ccc",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-03-12T05:27:23.942495Z",
     "iopub.status.busy": "2024-03-12T05:27:23.942330Z",
     "iopub.status.idle": "2024-03-12T05:27:23.945197Z",
     "shell.execute_reply": "2024-03-12T05:27:23.944706Z",
     "shell.execute_reply.started": "2024-03-12T05:27:23.942480Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_data = ModNetDataLoader(df_files_corrected,1080,True)\n",
    "transformer = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5), (0.5)\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "data = ModNetDataLoader(df_files_corrected, 512, transform=transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43281080-13ae-4bdb-9454-3333315f45ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T05:27:23.945961Z",
     "iopub.status.busy": "2024-03-12T05:27:23.945817Z",
     "iopub.status.idle": "2024-03-12T05:27:23.991931Z",
     "shell.execute_reply": "2024-03-12T05:27:23.991520Z",
     "shell.execute_reply.started": "2024-03-12T05:27:23.945948Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module://matplotlib_inline.backend_inline\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "print(matplotlib.get_backend())\n",
    "# If necessary, switch to an interactive backend, e.g., 'TkAgg', 'Qt5Agg'\n",
    "# matplotlib.use('TkAgg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737ecfb6-fcf4-49b2-8556-2a0c3cf63c75",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-03-12T06:13:03.760768Z",
     "iopub.status.busy": "2024-03-12T06:13:03.760510Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "bs = 16         # batch size\n",
    "lr = 0.01       # learn rate\n",
    "epochs = 40     # total epochs\n",
    "train_dataloader = DataLoader(data, batch_size=8, shuffle=True)\n",
    "modnet = torch.nn.DataParallel(MODNet()).cuda()\n",
    "optimizer = torch.optim.SGD(modnet.parameters(), lr=lr, momentum=0.9)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=int(0.25 * epochs), gamma=0.1)\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "#dataloader = train-datalo(bs)     # NOTE: please finish this function\n",
    "\n",
    "#for epoch in range(0, epochs):\n",
    "#    for idx, (image, trimap, gt_matte) in enumerate(train_dataloader):\n",
    "#        semantic_loss, detail_loss, matte_loss = \\\n",
    "#            supervised_training_iter(modnet, optimizer, image, trimap, gt_matte)\n",
    "#        lr_scheduler.step()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize lists to store loss values\n",
    "semantic_losses, detail_losses, matte_losses = [], [], []\n",
    "\n",
    "plt.ion()  # Turn on interactive mode\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Training Loss Over Time')\n",
    "writer = SummaryWriter('runs/your_experiment_name')\n",
    "update_freq = 100  # Update the plot every 100 iterations\n",
    "for epoch in range(0, epochs):\n",
    "    for idx, (image, trimap, gt_matte) in enumerate(train_dataloader):\n",
    "        # Your training step\n",
    "        semantic_loss, detail_loss, matte_loss = supervised_training_iter(modnet, optimizer, image, trimap, gt_matte)\n",
    "        writer.add_scalar('semantic', semantic_loss, epoch)\n",
    "        writer.add_scalar('detail_loss', detail_loss, epoch)\n",
    "        writer.add_scalar('matte_loss', matte_loss, epoch)\n",
    "        semantic_losses.append(semantic_loss.item())\n",
    "        detail_losses.append(detail_loss.item())\n",
    "        matte_losses.append(matte_loss.item())\n",
    "\n",
    "#        if idx % update_freq == 0:\n",
    "#            # Efficiently update the plot\n",
    "#            ax.clear()\n",
    "#            if len(semantic_losses) > 0:\n",
    "#                ax.plot(semantic_losses, label='Semantic Loss')\n",
    "#            if len(detail_losses) > 0:\n",
    "#                ax.plot(detail_losses, label='Detail Loss')\n",
    "#            if len(matte_losses) > 0:\n",
    "#               ax.plot(matte_losses, label='Matte Loss')\n",
    "#            \n",
    "#            ax.legend()\n",
    "#            plt.draw()\n",
    "#            plt.pause(0.1)  # A slightly longer pause to ensure the GUI has time to update\n",
    "\n",
    "    lr_scheduler.step()\n",
    "\n",
    "plt.ioff()  # Turn off interactive mode when done to finalize the plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafa3e54-e29b-4999-b770-611ed6ae56ed",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.status.busy": "2024-03-12T05:31:56.080589Z",
     "iopub.status.idle": "2024-03-12T05:31:56.080779Z",
     "shell.execute_reply": "2024-03-12T05:31:56.080695Z",
     "shell.execute_reply.started": "2024-03-12T05:31:56.080686Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_xlabel('Iteration')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Training Loss Over Time')\n",
    "ax.plot(semantic_losses, label='Semantic Loss')\n",
    "ax.plot(detail_losses, label='Detail Loss')\n",
    "ax.plot(matte_losses, label='Matte Loss')\n",
    "ax.legend()\n",
    "plt.draw()\n",
    "plt.pause(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6bf727-8a67-4d38-aae8-75fafd49ccf5",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.status.busy": "2024-03-12T05:31:56.081733Z",
     "iopub.status.idle": "2024-03-12T05:31:56.081916Z",
     "shell.execute_reply": "2024-03-12T05:31:56.081838Z",
     "shell.execute_reply.started": "2024-03-12T05:31:56.081830Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def combined_display(image, matte):\n",
    "  # calculate display resolution\n",
    "  w, h = image.width, image.height\n",
    "  rw, rh = 800, int(h * 800 / (3 * w))\n",
    "  \n",
    "  # obtain predicted foreground\n",
    "  image = np.asarray(image)\n",
    "  if len(image.shape) == 2:\n",
    "    image = image[:, :, None]\n",
    "  if image.shape[2] == 1:\n",
    "    image = np.repeat(image, 3, axis=2)\n",
    "  elif image.shape[2] == 4:\n",
    "    image = image[:, :, 0:3]\n",
    "  matte = np.repeat(np.asarray(matte)[:, :, None], 3, axis=2) / 255\n",
    "  foreground = image * matte + np.full(image.shape, 255) * (1 - matte)\n",
    "  \n",
    "  # combine image, foreground, and alpha into one line\n",
    "  combined = np.concatenate((image, foreground, matte * 255), axis=1)\n",
    "  combined = Image.fromarray(np.uint8(combined)).resize((rw, rh))\n",
    "  return combined\n",
    "\n",
    "# visualize all images\n",
    "#image_names = os.listdir(input_folder)\n",
    "#for image_name in image_names:\n",
    "  #matte_name = image_name.split('.')[0] + '.png'\n",
    "  #image = Image.open(os.path.join(input_folder, image_name))\n",
    "  #matte = Image.open(os.path.join(output_folder, matte_name))\n",
    "  #display(combined_display(image, matte))\n",
    "  #print(image_name, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc18482-e26d-4032-b184-5674329b5d2e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-12T05:31:56.082418Z",
     "iopub.status.idle": "2024-03-12T05:31:56.082595Z",
     "shell.execute_reply": "2024-03-12T05:31:56.082515Z",
     "shell.execute_reply.started": "2024-03-12T05:31:56.082507Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"hello,world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c897331-4c30-4bd2-9b2f-2ac84716c965",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.status.busy": "2024-03-12T05:31:56.083197Z",
     "iopub.status.idle": "2024-03-12T05:31:56.083368Z",
     "shell.execute_reply": "2024-03-12T05:31:56.083293Z",
     "shell.execute_reply.started": "2024-03-12T05:31:56.083285Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a,b,c=modnet(data[1][0].unsqueeze(0).cuda(),False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f02ec78-55ac-436c-9841-5a83fe811ac8",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.status.busy": "2024-03-12T05:31:56.083898Z",
     "iopub.status.idle": "2024-03-12T05:31:56.084073Z",
     "shell.execute_reply": "2024-03-12T05:31:56.083988Z",
     "shell.execute_reply.started": "2024-03-12T05:31:56.083981Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(a.shape,c.shape)\n",
    "origin=transforms.ToPILImage()(data[1][0].squeeze().cuda())\n",
    "cc=transforms.ToPILImage()(c.squeeze().cuda())\n",
    "print(\"hi\")\n",
    "combined_display(origin,cc)\n",
    "#imb =transforms.ToPILImage()(im.squeeze().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6aab5c-c6a9-437d-ac72-7a572bb9d3df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
