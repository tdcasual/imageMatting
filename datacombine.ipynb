{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48066d45-a85e-4442-94a4-638ca84adce0",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-04-04T00:34:23.538406Z",
     "iopub.status.busy": "2024-04-04T00:34:23.537934Z",
     "iopub.status.idle": "2024-04-04T00:34:23.545580Z",
     "shell.execute_reply": "2024-04-04T00:34:23.544824Z",
     "shell.execute_reply.started": "2024-04-04T00:34:23.538373Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image, ImageOps\n",
    "import torch\n",
    "import random\n",
    "def composite_images(img_a_path, img_a_matte_path, img_b_path, img_b_matte_path, scale_factor, position):\n",
    "    # 加载图片A及其蒙版\n",
    "    img_a = Image.open(img_a_path).convert(\"RGBA\")\n",
    "    img_a_matte = Image.open(img_a_matte_path).convert(\"L\")\n",
    "    \n",
    "    # 加载图片B及其蒙版\n",
    "    img_b = Image.open(img_b_path).convert(\"RGBA\")\n",
    "    img_b_matte = Image.open(img_b_matte_path).convert(\"L\")\n",
    "\n",
    "    # 缩放图片B及其蒙版\n",
    "    new_size = (int(img_b.width * scale_factor), int(img_b.height * scale_factor))\n",
    "    img_b_resized = img_b.resize(new_size, Image.Resampling.LANCZOS)\n",
    "    img_b_matte_resized = img_b_matte.resize(new_size, Image.Resampling.LANCZOS)\n",
    "\n",
    "    # 使用图片B的蒙版创建一个只有人物的版本（没有背景）\n",
    "    img_b_person = Image.composite(img_b_resized, Image.new(\"RGBA\", img_b_resized.size, (0, 0, 0, 0)), img_b_matte_resized)\n",
    "\n",
    "    # 准备图片A的背景（不包括人物A）\n",
    "    img_a_background = Image.composite(Image.new(\"RGBA\", img_a.size, (0, 0, 0, 0)), img_a, ImageOps.invert(img_a_matte))\n",
    "\n",
    "    # 将图片B的人物放置到图片A的指定位置\n",
    "    img_a_background.paste(img_b_person, position, img_b_person)\n",
    "\n",
    "    # 将图片A的人物重新放置到合成图像上，确保图片A的人物在最上层\n",
    "    final_img = Image.composite(img_a, img_a_background, img_a_matte)\n",
    "\n",
    "    # 显示或保存最终图像\n",
    "    return final_img  # 或 final_img.save(\"output_path.png\")\n",
    "\n",
    "# 调用函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29d4d7ae-f1ba-4d06-9e7b-c77a1c4a1a9f",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-04-04T00:34:25.945603Z",
     "iopub.status.busy": "2024-04-04T00:34:25.945039Z",
     "iopub.status.idle": "2024-04-04T00:34:25.956112Z",
     "shell.execute_reply": "2024-04-04T00:34:25.955366Z",
     "shell.execute_reply.started": "2024-04-04T00:34:25.945568Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def composite_images_with_random_parameters_clipping_rotation_and_cropping(img_a_path, img_a_matte_path, img_b_path, img_b_matte_path):\n",
    "    # 加载图片A以获取其尺寸\n",
    "    img_a = Image.open(img_a_path).convert(\"RGBA\")\n",
    "    \n",
    "    # 加载图片B\n",
    "    img_b = Image.open(img_b_path).convert(\"RGBA\")\n",
    "    \n",
    "    # 随机生成缩放因子，范围从0.5到1.5\n",
    "    scale_factor = random.uniform(0.5, 1.5)\n",
    "\n",
    "    # 如果scale_factor大于0.8，则对图片B进行随机裁剪\n",
    "    if scale_factor > 0.8:\n",
    "        # 计算裁剪尺寸，裁剪1/4到1/2的内容\n",
    "        crop_width = random.uniform(0.3, 0.5)/scale_factor * img_b.width\n",
    "        crop_height = random.uniform(0.3, 0.5)/scale_factor * img_b.height\n",
    "\n",
    "        # 计算裁剪的起始位置\n",
    "        start_x = random.randint(0, int(img_b.width - crop_width))\n",
    "        start_y = random.randint(0, int(img_b.height - crop_height))\n",
    "\n",
    "        # 应用裁剪\n",
    "        img_b = img_b.crop((start_x, start_y, start_x + crop_width, start_y + crop_height))\n",
    "\n",
    "    # 缩放图片B\n",
    "    img_b_resized = img_b.resize((int(img_b.width * scale_factor), int(img_b.height * scale_factor)), Image.Resampling.LANCZOS)\n",
    "    \n",
    "    # 随机生成旋转角度，范围从-15到15度\n",
    "    rotation_angle = random.uniform(-15, 15)\n",
    "    \n",
    "    # 旋转图片B\n",
    "    img_b_rotated = img_b_resized.rotate(rotation_angle, expand=True)\n",
    "\n",
    "    # 如果旋转后的图片B尺寸超过图片A，进行裁剪\n",
    "    if img_b_rotated.width > img_a.width or img_b_rotated.height > img_a.height:\n",
    "        img_b_rotated = img_b_rotated.crop((0, 0, min(img_a.width, img_b_rotated.width), min(img_a.height, img_b_rotated.height)))\n",
    "\n",
    "    # 生成随机位置\n",
    "    max_x_position = max(img_a.width - img_b_rotated.width, 0)\n",
    "    max_y_position = max(img_a.height - img_b_rotated.height, 0)\n",
    "    position = (random.randint(0, max_x_position), random.randint(0, max_y_position))\n",
    "\n",
    "    # 调用原始合成函数\n",
    "    return composite_images(img_a_path, img_a_matte_path, img_b_path, img_b_matte_path, scale_factor, position)\n",
    "def composite_images_from_df(df):\n",
    "    \"\"\"\n",
    "    从DataFrame中随机选择两张图片及其Alpha蒙版，并应用合成流程。\n",
    "    \n",
    "    参数:\n",
    "    - df: 包含至少两组图片路径的DataFrame，有两列：'FG'和'Alpha'。\n",
    "    \n",
    "    返回:\n",
    "    - PIL Image对象，表示合成后的图片。\n",
    "    \"\"\"\n",
    "    \n",
    "    # 确保df至少有两行\n",
    "    if len(df) < 2:\n",
    "        raise ValueError(\"DataFrame需要至少包含两行数据。\")\n",
    "    \n",
    "    # 随机选择两个不同的索引\n",
    "    idxs = random.sample(range(len(df)), 2)\n",
    "    a, b = idxs[0], idxs[1]\n",
    "    \n",
    "    # 从DataFrame中读取路径\n",
    "    a_img, a_alpha = df.iloc[a]['FG'], df.iloc[a]['Alpha']\n",
    "    b_img, b_alpha = df.iloc[b]['FG'], df.iloc[b]['Alpha']\n",
    "    \n",
    "    # 调用合成函数\n",
    "    return composite_images_with_random_parameters_clipping_rotation_and_cropping(\n",
    "        img_a_path=a_img, img_a_matte_path=a_alpha,\n",
    "        img_b_path=b_img, img_b_matte_path=b_alpha\n",
    "    ),Image.open(df.iloc[a]['Alpha']),df.iloc[a]['FG'].split(\"/\")[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4894385d-8b28-402b-9162-e457c0b94680",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-04-04T00:34:28.648300Z",
     "iopub.status.busy": "2024-04-04T00:34:28.647714Z",
     "iopub.status.idle": "2024-04-04T00:34:28.656258Z",
     "shell.execute_reply": "2024-04-04T00:34:28.655488Z",
     "shell.execute_reply.started": "2024-04-04T00:34:28.648266Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import uuid\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "# 在循环中\n",
    "\n",
    "# 假设ReadImage类和composite_images_from_df函数已正确定义\n",
    "\n",
    "def generate_composite_images(fg_dir, alpha_dir, target_dir, prefix, n,hot):\n",
    "    # 确保目标目录存在\n",
    "    if not os.path.isdir(fg_dir):\n",
    "        raise FileNotFoundError(f\"前景目录 '{fg_dir}' 不存在。\")\n",
    "    if not os.path.isdir(alpha_dir):\n",
    "        raise FileNotFoundError(f\"透明度蒙版目录 '{alpha_dir}' 不存在。\")\n",
    "    if not os.path.isdir(target_dir):\n",
    "        raise FileNotFoundError(f\"目标目录 '{target_dir}' 不存在。\")\n",
    "    # 读取图片和蒙版信息构建DataFrame\n",
    "    # 注意：根据实际ReadImage类的实现调整下面的代码\n",
    "    # files = ReadImage(fg_dir, alpha_dir).read_same_names()\n",
    "    hots = torch.load(hot)\n",
    "    # 存储生成的文件名\n",
    "    generated_filenames = []\n",
    "    \n",
    "    for _ in range(n):\n",
    "        # 执行合成操作，此处假设composite_images_from_df已经修改为返回两个Image对象\n",
    "        composite_image, composite_alpha,base_name = composite_images_from_df(files)\n",
    "        \n",
    "        # 生成唯一的文件名\n",
    "        unique_filename = f\"{prefix}_{uuid.uuid4().hex}.png\"\n",
    "        generated_filenames.append(unique_filename)\n",
    "        \n",
    "        # 保存合成图和蒙版\n",
    "        composite_image.save(os.path.join(fg_dir, unique_filename))\n",
    "        composite_alpha.save(os.path.join(alpha_dir, unique_filename))\n",
    "        hots[unique_filename] = copy.deepcopy(hots[base_name])\n",
    "        \n",
    "    # 保存文件名到文本文件\n",
    "    today_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    filenames_file_path = os.path.join(target_dir, f\"own_{today_str}.txt\")\n",
    "    torch.save(hots,hot)\n",
    "    with open(filenames_file_path, 'w') as f:\n",
    "        for filename in generated_filenames:\n",
    "            f.write(f\"{filename}\\n\")\n",
    "    return generated_filenames\n",
    "\n",
    "# 调用函数示例\n",
    "# generate_composite_images('/path/to/fg', '/path/to/alpha', '/path/to/target', 'prefix', 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a498ddf-b183-49f8-9c9a-01aca79dd673",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-04-04T00:34:34.130742Z",
     "iopub.status.busy": "2024-04-04T00:34:34.130265Z",
     "iopub.status.idle": "2024-04-04T00:34:34.137201Z",
     "shell.execute_reply": "2024-04-04T00:34:34.136491Z",
     "shell.execute_reply.started": "2024-04-04T00:34:34.130711Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def delete_listed_files(file_path, dir1, dir2):\n",
    "    \"\"\"\n",
    "    删除两个目录下，文件名列在file_path中的所有文件，最后删除file_path文件。\n",
    "\n",
    "    参数:\n",
    "    - file_path: 包含要删除的文件名列表的文件路径。\n",
    "    - dir1, dir2: 包含需要删除文件的目录路径。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 打开文件并读取文件名列表\n",
    "        with open(file_path, 'r') as file:\n",
    "            filenames = file.read().splitlines()\n",
    "        \n",
    "        # 在两个目录中循环删除文件\n",
    "        for dir in [dir1, dir2]:\n",
    "            for filename in filenames:\n",
    "                try:\n",
    "                    # 构建完整的文件路径\n",
    "                    full_path = os.path.join(dir, filename)\n",
    "                    # 如果文件存在，则删除\n",
    "                    if os.path.exists(full_path):\n",
    "                        os.remove(full_path)\n",
    "                        print(f\"已删除文件: {full_path}\")\n",
    "                    else:\n",
    "                        print(f\"未找到文件: {full_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"删除文件 {full_path} 时出错: {e}\")\n",
    "\n",
    "        # 最后删除包含文件名列表的文件本身\n",
    "        os.remove(file_path)\n",
    "        print(f\"已删除文件列表: {file_path}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"处理文件 {file_path} 时出错: {e}\")\n",
    "\n",
    "# 示例调用\n",
    "# delete_listed_files('path/to/filenames_file.txt', '/path/to/dir1', '/path/to/dir2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77276476-a7d4-4275-926e-07c26dc0b969",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-04-04T00:33:16.756330Z",
     "iopub.status.busy": "2024-04-04T00:33:16.755370Z",
     "iopub.status.idle": "2024-04-04T00:33:18.981639Z",
     "shell.execute_reply": "2024-04-04T00:33:18.980841Z",
     "shell.execute_reply.started": "2024-04-04T00:33:16.756275Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from wraptrain import ReadImage\n",
    "base_path = \"/mnt/data/Test/\"\n",
    "fg = base_path+\"Comp\"\n",
    "matte= base_path+\"Alpha\"\n",
    "files = ReadImage(fg,matte).read_same_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cfa7ee8-04fb-4c4f-96a1-99c60fd9f496",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-04-04T00:33:20.006937Z",
     "iopub.status.busy": "2024-04-04T00:33:20.006143Z",
     "iopub.status.idle": "2024-04-04T00:33:20.013635Z",
     "shell.execute_reply": "2024-04-04T00:33:20.012899Z",
     "shell.execute_reply.started": "2024-04-04T00:33:20.006900Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "987657b6-1de5-4297-84f0-5e63b751616c",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-04-04T04:35:46.123987Z",
     "iopub.status.busy": "2024-04-04T04:35:46.123498Z",
     "iopub.status.idle": "2024-04-04T04:35:46.127807Z",
     "shell.execute_reply": "2024-04-04T04:35:46.126924Z",
     "shell.execute_reply.started": "2024-04-04T04:35:46.123952Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#generate_composite_images(fg,matte,base_path,\"firstown\",250,base_path+\"Heatmaps.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5366ed08-c06a-4a48-a67d-bb42837ebfdf",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-04-03T20:45:24.453848Z",
     "iopub.status.busy": "2024-04-03T20:45:24.453498Z",
     "iopub.status.idle": "2024-04-03T20:45:24.458225Z",
     "shell.execute_reply": "2024-04-03T20:45:24.457602Z",
     "shell.execute_reply.started": "2024-04-03T20:45:24.453822Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pexels-vincenzo-giove-1925482.png'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'/mnt/data/Train/FG/pexels-vincenzo-giove-1925482.png'.split(\"/\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6dbbe8-2871-403e-a98d-a5fd1019c630",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-04-03T20:45:24.476169Z",
     "iopub.status.busy": "2024-04-03T20:45:24.475644Z",
     "iopub.status.idle": "2024-04-03T20:45:24.478733Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#delete_listed_files(own_file,fg,matte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43d9c3b-e4b9-488f-8b05-ad23dcdd0462",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-04-03T20:45:24.479773Z",
     "iopub.status.busy": "2024-04-03T20:45:24.479559Z",
     "iopub.status.idle": "2024-04-03T20:45:24.482483Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#a,b=13,19\n",
    "#a_img, a_alpha, b_img, b_alpha = files[\"FG\"][a],files[\"Alpha\"][a],files[\"FG\"][b],files[\"Alpha\"][b]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3df6d55f-4e3e-4245-840e-76c2dda67483",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-04-04T05:06:55.753267Z",
     "iopub.status.busy": "2024-04-04T05:06:55.752669Z",
     "iopub.status.idle": "2024-04-04T05:25:17.782729Z",
     "shell.execute_reply": "2024-04-04T05:25:17.781738Z",
     "shell.execute_reply.started": "2024-04-04T05:06:55.753236Z"
    },
    "tags": []
   },
   "source": [
    "import torch\n",
    "from torchvision.models.detection import keypointrcnn_resnet50_fpn\n",
    "from torchvision.transforms.functional import to_tensor\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "\n",
    "# 加载模型并设置为评估模式\n",
    "model = keypointrcnn_resnet50_fpn(pretrained=True).eval()\n",
    "model.cuda()\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "def generate_heatmap(keypoints, output_shape, original_shape, sigma=2):\n",
    "    \"\"\"\n",
    "    从关键点生成热力图。\n",
    "    \"\"\"\n",
    "    scale_x = output_shape[1] / original_shape[1]\n",
    "    scale_y = output_shape[0] / original_shape[0]\n",
    "    heatmaps = np.zeros((17, output_shape[0], output_shape[1]), dtype=np.float32)\n",
    "    for i, (x, y, v) in enumerate(keypoints):\n",
    "        if v > 0:\n",
    "            x = int(scale_x * x)\n",
    "            y = int(scale_y * y)\n",
    "            if 0 <= x < output_shape[1] and 0 <= y < output_shape[0]:\n",
    "                heatmaps[i, y, x] = 1\n",
    "                heatmaps[i] = gaussian_filter(heatmaps[i], sigma=sigma)\n",
    "    return heatmaps\n",
    "\n",
    "# 处理图片并保存结果\n",
    "from wraptrain import ReadImage,OriginModNetDataLoader,ImageMatteLoader,ModNetImageGenerator,NetTrainer\n",
    "\n",
    "\n",
    "results = {}\n",
    "\n",
    "heatmaps_dir = '/mnt/data/Test/newHeatmaps.pt'\n",
    "base_path = \"/mnt/data/Test/\"\n",
    "fg = base_path+\"Comp\"\n",
    "matte= base_path+\"Alpha\"\n",
    "\n",
    "original_shape=[512,512]\n",
    "files = ReadImage(fg,matte).read_same_names()\n",
    "all_data = OriginModNetDataLoader(files,original_shape)\n",
    "images_dir = fg\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # 可以添加其他的转换操作，比如归一化等\n",
    "])\n",
    "\n",
    "\n",
    "#images_dir = fg\n",
    "#output_shape = (128, 128)  # 目标热力图尺寸\n",
    "files = files\n",
    "image_data = all_data\n",
    "results={}\n",
    "fileslens = len(image_data)\n",
    "pics = ImageMatteLoader(files)\n",
    "for i in range(fileslens):\n",
    "    image = pics.show(i,[512,512])[0]\n",
    "    #image = Image.open(path).convert(\"RGB\")\n",
    "    path = files[\"FG\"][i]\n",
    "    image_tensor = transform(image).unsqueeze(0).cuda()\n",
    "    #image_tensor = image_data[i][0][None,:,:,:].cuda()\n",
    "    file_name = path.split('/')[-1]\n",
    "            # 模型预测\n",
    "    output = model(image_tensor)\n",
    "    if len(output[0]['keypoints']) > 0:  # 确保至少检测到一个目标\n",
    "        keypoints = output[0]['keypoints'][0].cpu().numpy()  # 只处理第一个检测到的目标\n",
    "\n",
    "                # 生成热力图\n",
    "        #heatmaps = generate_heatmap(keypoints, output_shape, original_shape)\n",
    "\n",
    "                # 保存结果\n",
    "        #print(file_name)\n",
    "        results[file_name] = keypoints\n",
    "\n",
    "\n",
    "torch.save(results, heatmaps_dir)\n",
    "print(\"save \",len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "623dcedb-e48e-47b8-93f0-905e15e3c5d4",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-04-04T04:36:46.494591Z",
     "iopub.status.busy": "2024-04-04T04:36:46.493702Z",
     "iopub.status.idle": "2024-04-04T04:36:48.691648Z",
     "shell.execute_reply": "2024-04-04T04:36:48.690693Z",
     "shell.execute_reply.started": "2024-04-04T04:36:46.494549Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/data/Test/Comp/attractive-man-with-blue-eyes-smiling-with-joy-showing-ok-sign-with-both-hands-glad-after-meeting-with-his-girlfriend-isolated-human-facial-expressions-emotions_1.png\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'visualize_keypoints' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(output[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeypoints\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# 确保至少检测到一个目标\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     keypoints \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeypoints\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()  \u001b[38;5;66;03m# 只处理第一个检测到的目标\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m     \u001b[43mvisualize_keypoints\u001b[49m(p15, keypoints)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#keypoints\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'visualize_keypoints' is not defined"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# 定义图像转换\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # 可以添加其他的转换操作，比如归一化等\n",
    "])\n",
    "\n",
    "# 加载模型并设置为评估模式\n",
    "model = keypointrcnn_resnet50_fpn(pretrained=True).eval()\n",
    "model.cuda()\n",
    "torch.set_grad_enabled(False)\n",
    "i = 101\n",
    "\n",
    "path = files[\"FG\"][i]\n",
    "print(path)\n",
    "#image = Image.open(path).convert(\"RGB\")\n",
    "image = Image.open(path)\n",
    "# 对图像进行转换\n",
    "image_tensor = transform(image).unsqueeze(0).cuda()  # 添加额外的维度并移动到 GPU 上\n",
    "\n",
    "# file_name = path.split('/')[-1]  # 这行代码没有用到，可以删除\n",
    "\n",
    "# 模型预测\n",
    "output = model(image_tensor)\n",
    "if len(output[0]['keypoints']) > 0:  # 确保至少检测到一个目标\n",
    "    keypoints = output[0]['keypoints'][0].cpu().numpy()  # 只处理第一个检测到的目标\n",
    "    visualize_keypoints(p15, keypoints)\n",
    "#keypoints"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
